{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/.pyenv/versions/3.12.2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.tools_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flipping every image in a folder for data augmentation\n",
    "def flip_png(images_folder):\n",
    "    for emotion_folder in sorted(os.listdir(images_folder)):\n",
    "        # create path for each emotion folder\n",
    "        emotion_folder_path = os.path.join(images_folder, emotion_folder)\n",
    "\n",
    "         # skip the .DS_Store file\n",
    "        if emotion_folder == '.DS_Store': continue\n",
    "\n",
    "        for filename in sorted(os.listdir(emotion_folder_path)):\n",
    "\n",
    "            # metadata \n",
    "            if filename.endswith('.csv'): \n",
    "                # read the metadata file\n",
    "                metadata_df = pd.read_csv(os.path.join(emotion_folder_path, filename))\n",
    "\n",
    "                # convert the file_attributes column to a dictionary\n",
    "                metadata_df['file_attributes'] = metadata_df['file_attributes'].apply(json.loads)\n",
    "\n",
    "                # make a new column for age\n",
    "                metadata_df['age'] = metadata_df['file_attributes'].apply(lambda x: x['age'] if 'age' in x else np.nan)\n",
    "\n",
    "                # make a new column for gender\n",
    "                metadata_df['gender'] = metadata_df['file_attributes'].apply(lambda x: x['gender'])\n",
    "\n",
    "                new_rows = []\n",
    "                for index, row in metadata_df.iterrows():\n",
    "                    # get the filename\n",
    "                    image_filename = row['filename']\n",
    "\n",
    "                    # open the image\n",
    "                    image_path = os.path.join(emotion_folder_path, image_filename)\n",
    "                    img        = Image.open(image_path)\n",
    "\n",
    "                    flipped_image = img.transpose(Image.FLIP_TOP_BOTTOM) # flip\n",
    "\n",
    "                    # extract the filename (without extension) from the original image path\n",
    "                    filename_wo_extension = os.path.splitext(image_path)[0]\n",
    "\n",
    "                    # save it\n",
    "                    flipped_image.save(filename_wo_extension + '_flipped.png')\n",
    "\n",
    "                    # create a new row for the metadata dataframe\n",
    "                    new_row = row.copy()\n",
    "                    new_row['filename'] = os.path.basename(filename_wo_extension + '_flipped.png')\n",
    "                    new_rows.append(new_row)\n",
    "\n",
    "\n",
    "                new_rows_df = pd.DataFrame(new_rows)\n",
    "                metadata_df = pd.concat([metadata_df, new_rows_df], ignore_index=True)\n",
    "\n",
    "                # convert metadata dataframe to csv\n",
    "                metadata_df.to_csv(os.path.join(emotion_folder_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images to dictionary conversion\n",
    "def png_to_dict(images_folder):\n",
    "    # create 2 empty lists, one for features and one for labels\n",
    "    images = {}\n",
    "\n",
    "    for emotion_folder in sorted(os.listdir(images_folder)):\n",
    "        # create path for each emotion folder\n",
    "        emotion_folder_path = os.path.join(images_folder, emotion_folder)\n",
    "\n",
    "        # skip the .DS_Store file\n",
    "        if emotion_folder == '.DS_Store': continue\n",
    "\n",
    "        # loop through all the files in the folder and find metadata csv file\n",
    "        for filename in sorted(os.listdir(emotion_folder_path)):\n",
    "\n",
    "            # metadata \n",
    "            if filename.endswith('.csv'): \n",
    "                # read the csv file\n",
    "                metadata_df = pd.read_csv(os.path.join(emotion_folder_path, filename))\n",
    "\n",
    "                if 'age' not in metadata_df.columns and 'gender' not in metadata_df.columns:\n",
    "                    # convert the file_attributes column to a dictionary\n",
    "                    metadata_df['file_attributes'] = metadata_df['file_attributes'].apply(json.loads)\n",
    "\n",
    "                    # make a new column for age\n",
    "                    metadata_df['age'] = metadata_df['file_attributes'].apply(lambda x: x['age'] if 'age' in x else np.nan)\n",
    "\n",
    "                    # make a new column for gender\n",
    "                    metadata_df['gender'] = metadata_df['file_attributes'].apply(lambda x: x['gender'])\n",
    "\n",
    "                for index, row in metadata_df.iterrows():\n",
    "                    # get the filename\n",
    "                    image_filename = row['filename']\n",
    "\n",
    "                    # open the image\n",
    "                    image_path = os.path.join(emotion_folder_path, image_filename)\n",
    "                    img        = Image.open(image_path)\n",
    "\n",
    "                    # convert the image into a numpy array\n",
    "                    img_array = np.array(img)\n",
    "\n",
    "                    # flatten the array to size 2304 (48x48)\n",
    "                    img_array_flat = np.array(img_array.flatten())\n",
    "\n",
    "                    # get gender\n",
    "                    img_gender = metadata_df[metadata_df['filename'] == image_filename]['gender']\n",
    "\n",
    "                    # get age\n",
    "                    img_age = metadata_df[metadata_df['filename'] == image_filename]['age']\n",
    "\n",
    "                    # add to dictionary (key: filename, value: dictionary with np array, path, age, gender, emotion)\n",
    "                    images[f'{emotion_folder}/{image_filename}'] = {'np_array': img_array_flat,\n",
    "                                                              'path': image_path,\n",
    "                                                              'age': img_age,\n",
    "                                                              'gender': img_gender,\n",
    "                                                              'emotion': emotion_folder}\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flip_png('data_w_metadata/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = png_to_dict('data_w_metadata/train')\n",
    "test_images = png_to_dict('data_w_metadata/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for key, value in train_images.items():\n",
    "    X_train.append(value['np_array'])\n",
    "    y_train.append(value['emotion'])\n",
    "\n",
    "for key, value in test_images.items():\n",
    "    X_test.append(value['np_array'])\n",
    "    y_test.append(value['emotion'])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the features\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "# fit the dataset to the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# scale X and replace it with its original counterpart\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
